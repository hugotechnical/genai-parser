import os
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Tuple

from fastapi import APIRouter, UploadFile, File, HTTPException, Request
from fastapi.responses import JSONResponse
from slowapi import Limiter
from slowapi.util import get_remote_address

from app.services.parser_factory import ParserFactory
from app.services.file_service import save_upload_to_temp
from app.models import FileResponse
from app.config import settings
from app.utils import get_logger
from app.utils.pdf_utils import decide_should_ocr_file


router = APIRouter()
logger = get_logger(__name__)

# --- CONFIGURATION ---

# Rate limiter
limiter = Limiter(key_func=get_remote_address)

HEAVY_EXTENSIONS = settings.heavy_extensions or {'pdf'}

# C·∫•u h√¨nh gi·ªõi h·∫°n Semaphore
LIMIT_HEAVY = settings.max_concurrent_parser_heavy or 2  
LIMIT_LIGHT = settings.max_concurrent_parser_light or 10 

MAX_FILE_SIZE = settings.max_file_size * 1024 * 1024
PARSE_TIMEOUT = settings.timeout or 300 

sem_heavy = asyncio.Semaphore(LIMIT_HEAVY)
sem_light = asyncio.Semaphore(LIMIT_LIGHT)

executor = ThreadPoolExecutor(max_workers=LIMIT_HEAVY + LIMIT_LIGHT + 4)


@router.get("/", summary="Health Check")
@limiter.limit(settings.rate_limit)
def health_check(request: Request):
    return {"status": "ok"}


@router.post("/sdlc/convert-document", response_model=FileResponse)
@limiter.limit(settings.rate_limit)
async def upload_file(request: Request, file: UploadFile = File(...)):
    temp_path = None
    file_id = None
    config = dict()
    start_time = time.time()
    try:
        logger.info("üì§ ƒê√£ nh·∫≠n file upload: filename=%s content_type=%s", file.filename, file.content_type)

        # 1. ƒê·ªçc n·ªôi dung file
        content = await file.read()
        file_size = len(content)

        if file_size > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"K√≠ch th∆∞·ªõc file v∆∞·ª£t qu√° gi·ªõi h·∫°n {MAX_FILE_SIZE / (1024*1024):.2f}MB"
            )

        # 2. L∆∞u file t·∫°m
        file_id, temp_path = await save_upload_to_temp(file.filename, content)
        logger.debug("üóÇÔ∏è File t·∫°m l∆∞u t·∫°i: %s", temp_path)

        # 3. X√°c ƒë·ªãnh lo·∫°i file v√† ch·ªçn Semaphore ph√π h·ª£p
        file_ext = file.filename.split(".")[-1].lower() if "." in file.filename else ""
        
        parser = ParserFactory.get_parser(file_ext)
        if parser is None:
            raise HTTPException(status_code=400, detail=f"Unsupported file type: {file_ext}")

        # Logic ch·ªçn lane (Ph√¢n lu·ªìng)
        if file_ext in HEAVY_EXTENSIONS:
            if file_ext == "pdf":
                is_scan = decide_should_ocr_file(temp_path)["should_ocr_file"]
                if is_scan:
                    target_semaphore = sem_heavy
                    lane_name = "HEAVY (OCR/PDF)"
                    config["is_pdf_scan"] = True
                else:
                    target_semaphore = sem_light
                    lane_name = "LIGHT (Text/Doc/PDF native)"
                    config["is_pdf_scan"] = False
        else:
            target_semaphore = sem_light
            lane_name = "LIGHT (Text/Doc/PDF native)"
            config["is_pdf_scan"] = False

        # 4. Fail-fast: N·∫øu lane ƒëang qu√° t·∫£i, reject ngay ƒë·ªÉ client kh√¥ng ch·ªù
        if target_semaphore.locked():
            logger.warning("‚ö†Ô∏è %s Lane qu√° t·∫£i (%s request), t·ª´ ch·ªëi: %s", 
                           lane_name, 
                           LIMIT_HEAVY if lane_name.startswith("HEAVY") else LIMIT_LIGHT,
                           file.filename)
            # Tr·∫£ v·ªÅ 429 ƒë·ªÉ client bi·∫øt server b·∫≠n, c√≥ th·ªÉ retry sau
            raise HTTPException(status_code=429, detail=f"Server ƒëang b·∫≠n x·ª≠ l√Ω nhi·ªÅu file {lane_name}, vui l√≤ng th·ª≠ l·∫°i sau.")

        loop = asyncio.get_running_loop()
        
        # 5. X·ª≠ l√Ω Parse
        try:
            async with target_semaphore:
                logger.info("üöÄ B·∫Øt ƒë·∫ßu parse (%s): %s", lane_name, file.filename)
                
                # Ch·∫°y blocking code trong ThreadPoolExecutor
                # D√πng asyncio.wait_for ƒë·ªÉ set timeout c·ª©ng, tr√°nh treo vƒ©nh vi·ªÖn
                parsed_result = await asyncio.wait_for(
                    loop.run_in_executor(executor, lambda: parser.parse(temp_path, config)),
                    timeout=PARSE_TIMEOUT
                )
                
        except asyncio.TimeoutError:
            logger.error("‚è∞ Parse timeout (%ss): %s", PARSE_TIMEOUT, file.filename)
            raise HTTPException(status_code=408, detail="File x·ª≠ l√Ω qu√° l√¢u (Timeout), vui l√≤ng ki·ªÉm tra l·∫°i file.")

        if not parsed_result.is_success:
            raise HTTPException(status_code=400, detail=parsed_result.failed_reason)

        elapsed_time = time.time() - start_time
        logger.info(f"‚úÖ {elapsed_time}s Parsed th√†nh c√¥ng: id={file_id} ext={file_ext} lane={lane_name}")

        return FileResponse(
            id=file_id,
            file_name=file.filename,
            file_size=file_size,
            file_type=file.content_type,
            extracted_content=parsed_result.content
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.exception("‚ùå Failed to process upload: filename=%s error=%s", file.filename, str(e))
        raise HTTPException(status_code=500, detail=f"L·ªói khi x·ª≠ l√Ω file: {str(e)}")
    finally:
        # 6. Cleanup
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
                logger.debug("üßπ ƒê√£ xo√° file t·∫°m: %s", temp_path)
            except Exception as cleanup_err:
                logger.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ xo√° file t·∫°m %s: %s", temp_path, cleanup_err)