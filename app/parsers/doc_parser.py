import shutil
import subprocess
import tempfile
import os
import uuid
from lxml import etree
import zipfile

from pathlib import Path
from docx import Document
from typing import List, Tuple
from zipfile import ZipFile
import xml.etree.ElementTree as ET
from app.parsers.base_parser import BaseParser
from app.utils.logger import setup_logger
from app.models import ParsedResult


class DocParser(BaseParser):
    def __init__(self):
        self.logger = setup_logger(__name__)

    def _convert_doc_to_docx(self, doc_path: Path) -> Path:
        """Convert file .doc sang .docx b·∫±ng LibreOffice (CLI)."""
        temp_dir = tempfile.mkdtemp()
        output_path = Path(temp_dir) / (doc_path.stem + ".docx")
        
        # T·∫°o th∆∞ m·ª•c profile ri√™ng
        profile_dir = Path(f"/tmp/lo_profile_{uuid.uuid4().hex}")
        profile_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            self.logger.info(f"üîÑ Converting .doc ‚Üí .docx: {doc_path.name}")
            
            # Ki·ªÉm tra file ƒë·∫ßu v√†o
            if not doc_path.exists():
                raise FileNotFoundError(f"File kh√¥ng t·ªìn t·∫°i: {doc_path}")
            
            if not os.access(doc_path, os.R_OK):
                raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn ƒë·ªçc file: {doc_path}")
            
            # Ki·ªÉm tra quy·ªÅn ghi v√†o th∆∞ m·ª•c t·∫°m
            if not os.access(temp_dir, os.W_OK):
                raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn ghi v√†o th∆∞ m·ª•c t·∫°m: {temp_dir}")
            
            # Th·ª≠ chuy·ªÉn ƒë·ªïi v·ªõi nhi·ªÅu t√πy ch·ªçn kh√°c nhau
            conversion_methods = [
                # Ph∆∞∆°ng ph√°p 1: Kh√¥ng s·ª≠ d·ª•ng Java
                ["soffice", "--headless", f"-env:UserInstallation=file://{profile_dir}", 
                "--norestore", "--nofirststartwizard", "--nologo", "--convert-to", "docx", 
                "--outdir", temp_dir, str(doc_path)],
                
                # Ph∆∞∆°ng ph√°p 2: S·ª≠ d·ª•ng b·ªô l·ªçc c·ª• th·ªÉ
                ["soffice", "--headless", f"-env:UserInstallation=file://{profile_dir}", 
                "--convert-to", "docx:MS Word 2007 XML", "--outdir", temp_dir, str(doc_path)],
                
                # Ph∆∞∆°ng ph√°p 3: Th·ª≠ v·ªõi libreoffice thay v√¨ soffice
                ["libreoffice", "--headless", f"-env:UserInstallation=file://{profile_dir}", 
                "--convert-to", "docx", "--outdir", temp_dir, str(doc_path)]
            ]
            
            success = False
            error_messages = []
            
            for i, cmd in enumerate(conversion_methods):
                try:
                    self.logger.info(f"ƒêang th·ª≠ ph∆∞∆°ng ph√°p chuy·ªÉn ƒë·ªïi {i+1}/{len(conversion_methods)}")
                    
                    result = subprocess.run(
                        cmd,
                        check=False,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        timeout=300
                    )
                    
                    # Ki·ªÉm tra k·∫øt qu·∫£ v√† ƒë·∫£m b·∫£o file t·ªìn t·∫°i
                    if result.returncode == 0:
                        # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng
                        if output_path.exists():
                            success = True
                            self.logger.info(f"‚úÖ Convert th√†nh c√¥ng: {output_path}")
                            # ƒê·∫£m b·∫£o file c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c
                            if not os.access(output_path, os.R_OK):
                                os.chmod(output_path, 0o644)  # Th√™m quy·ªÅn ƒë·ªçc
                            break
                        else:
                            # T√¨m ki·∫øm file .docx trong th∆∞ m·ª•c ƒë·∫ßu ra
                            docx_files = list(Path(temp_dir).glob("*.docx"))
                            if docx_files:
                                output_path = docx_files[0]
                                success = True
                                self.logger.info(f"‚úÖ T√¨m th·∫•y file chuy·ªÉn ƒë·ªïi v·ªõi t√™n kh√°c: {output_path}")
                                # ƒê·∫£m b·∫£o file c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c
                                if not os.access(output_path, os.R_OK):
                                    os.chmod(output_path, 0o644)  # Th√™m quy·ªÅn ƒë·ªçc
                                break
                            else:
                                stderr = result.stderr.decode('utf-8', errors='replace')
                                error_messages.append(f"File kh√¥ng ƒë∆∞·ª£c t·∫°o ra m·∫∑c d√π qu√° tr√¨nh chuy·ªÉn ƒë·ªïi th√†nh c√¥ng: {stderr}")
                    else:
                        stderr = result.stderr.decode('utf-8', errors='replace')
                        error_messages.append(stderr)
                        self.logger.warning(f"‚ö†Ô∏è Ph∆∞∆°ng ph√°p chuy·ªÉn ƒë·ªïi th·∫•t b·∫°i: {stderr}")
                except Exception as e:
                    error_messages.append(str(e))
                    self.logger.warning(f"‚ö†Ô∏è L·ªói khi th·ª≠ ph∆∞∆°ng ph√°p chuy·ªÉn ƒë·ªïi: {e}")
            
            # D·ªçn d·∫πp th∆∞ m·ª•c profile t·∫°m
            try:
                shutil.rmtree(profile_dir, ignore_errors=True)
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x√≥a th∆∞ m·ª•c profile t·∫°m: {e}")
            
            if not success:
                # N·∫øu kh√¥ng th√†nh c√¥ng v·ªõi t·∫•t c·∫£ c√°c ph∆∞∆°ng ph√°p
                raise FileNotFoundError(f"Kh√¥ng t·∫°o ƒë∆∞·ª£c file .docx sau khi convert. L·ªói: {'; '.join(error_messages)}")
            
            # Ki·ªÉm tra l·∫°i m·ªôt l·∫ßn n·ªØa tr∆∞·ªõc khi tr·∫£ v·ªÅ
            if not output_path.exists():
                raise FileNotFoundError(f"File .docx kh√¥ng t·ªìn t·∫°i sau khi chuy·ªÉn ƒë·ªïi: {output_path}")
                
            return output_path
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói khi convert .doc ‚Üí .docx: {e}")
            raise



    def _process_paragraph(self, para_element, ns) -> str:
        """
        X·ª≠ l√Ω m·ªôt ph·∫ßn t·ª≠ XML c·ªßa ƒëo·∫°n vƒÉn (<w:p>) v√† tr·∫£ v·ªÅ chu·ªói vƒÉn b·∫£n ho√†n ch·ªânh
        c√≥ gi·ªØ l·∫°i ƒë·ªãnh d·∫°ng c∆° b·∫£n (in ƒë·∫≠m, in nghi√™ng, ch·ªØ to).
        """
        para_text_parts = []
        
        # Ki·ªÉm tra xem ƒëo·∫°n vƒÉn c√≥ ph·∫£i l√† heading kh√¥ng
        p_style = para_element.xpath('./w:pPr/w:pStyle', namespaces=ns)
        is_heading = False
        heading_level = 0
        
        if p_style:
            style_val = p_style[0].get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', '')
            if style_val.startswith('Heading'):
                is_heading = True
                try:
                    heading_level = int(style_val.replace('Heading', ''))
                except ValueError:
                    heading_level = 1
        
        nodes = para_element.xpath('.//w:r | .//w:br | .//w:tab', namespaces=ns)
        
        for node in nodes:
            tag = etree.QName(node.tag).localname
            
            if tag == 'r': 
                # Ki·ªÉm tra ƒë·ªãnh d·∫°ng c·ªßa run
                run_props = node.xpath('./w:rPr', namespaces=ns)
                is_bold = node.xpath('./w:rPr/w:b', namespaces=ns)
                is_italic = node.xpath('./w:rPr/w:i', namespaces=ns)
                
                # Ki·ªÉm tra k√≠ch th∆∞·ªõc font
                sz_elements = node.xpath('./w:rPr/w:sz', namespaces=ns)
                font_size = None
                if sz_elements:
                    font_size_val = sz_elements[0].get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val')
                    if font_size_val:
                        font_size = int(font_size_val) / 2  # Chuy·ªÉn ƒë·ªïi t·ª´ half-points sang points
                
                text_nodes = node.xpath('.//w:t', namespaces=ns)
                run_text = ''.join(t.text for t in text_nodes if t.text is not None)

                if not run_text:
                    continue

                # √Åp d·ª•ng ƒë·ªãnh d·∫°ng
                formatted_text = run_text
                
                # √Åp d·ª•ng in ƒë·∫≠m n·∫øu c√≥
                if is_bold:
                    formatted_text = f"**{formatted_text}**"
                    
                # √Åp d·ª•ng in nghi√™ng n·∫øu c√≥
                if is_italic:
                    formatted_text = f"*{formatted_text}*"
                    
                # N·∫øu l√† ph·∫ßn ƒë∆∞·ª£c ch√®n th√™m
                if node.xpath('ancestor::w:ins', namespaces=ns):
                    para_text_parts.append(formatted_text)
                else:
                    para_text_parts.append(formatted_text)

            elif tag == 'br':
                para_text_parts.append('\n')
                
            elif tag == 'tab':
                para_text_parts.append('\t')
        
        result = ''.join(para_text_parts)
        
        # N·∫øu l√† heading, th√™m d·∫•u # t∆∞∆°ng ·ª©ng
        if is_heading and heading_level > 0:
            result = '#' * heading_level + ' ' + result
        
        return result


    def _process_table(self, table_element, ns) -> str:
        """
        X·ª≠ l√Ω m·ªôt ph·∫ßn t·ª≠ XML c·ªßa b·∫£ng (<w:tbl>) v√† chuy·ªÉn ƒë·ªïi n√≥ th√†nh ƒë·ªãnh d·∫°ng Markdown,
        c√≥ h·ªó tr·ª£ x·ª≠ l√Ω merge cells v√† vmerge (merge rows).
        """
        table_markdown_lines = []
        rows = table_element.xpath('./w:tr', namespaces=ns)
        
        if not rows:
            return ""
        
        # X√°c ƒë·ªãnh s·ªë c·ªôt th·ª±c t·∫ø c·ªßa b·∫£ng
        grid_cols = table_element.xpath('./w:tblGrid/w:gridCol', namespaces=ns)
        num_columns = len(grid_cols) if grid_cols else 0
        
        if num_columns == 0:
            # T√≠nh t·ªïng s·ªë c·ªôt t·ª´ t·∫•t c·∫£ c√°c h√†ng, l·∫•y h√†ng c√≥ nhi·ªÅu c·ªôt nh·∫•t
            for row in rows:
                cells = row.xpath('./w:tc', namespaces=ns)
                row_cols = 0
                for cell in cells:
                    grid_span = cell.xpath('./w:tcPr/w:gridSpan', namespaces=ns)
                    if grid_span:
                        span_val = grid_span[0].get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val')
                        row_cols += int(span_val) if span_val else 1
                    else:
                        row_cols += 1
                num_columns = max(num_columns, row_cols)
        
        # Theo d√µi c√°c √¥ ƒë√£ ƒë∆∞·ª£c merge theo chi·ªÅu d·ªçc
        vmerge_tracking = [None] * num_columns
        
        # T·∫°o c·∫•u tr√∫c d·ªØ li·ªáu ƒë·ªÉ l∆∞u th√¥ng tin v·ªÅ c√°c √¥ ƒë∆∞·ª£c merge
        table_data = []
        cell_spans = []  # L∆∞u th√¥ng tin v·ªÅ span c·ªßa c√°c √¥
        
        # Ph√¢n t√≠ch c·∫•u tr√∫c b·∫£ng v√† l∆∞u th√¥ng tin v·ªÅ c√°c √¥ ƒë∆∞·ª£c merge
        for i, row_element in enumerate(rows):
            row_data = [""] * num_columns
            row_spans = [1] * num_columns  # M·∫∑c ƒë·ªãnh m·ªói √¥ chi·∫øm 1 c·ªôt
            row_cells = row_element.xpath('./w:tc', namespaces=ns)
            col_index = 0
            
            for cell_element in row_cells:
                # B·ªè qua n·∫øu ƒë√£ v∆∞·ª£t qu√° s·ªë c·ªôt
                if col_index >= num_columns:
                    break
                    
                # Ki·ªÉm tra xem c·ªôt hi·ªán t·∫°i c√≥ b·ªã ·∫£nh h∆∞·ªüng b·ªüi vmerge t·ª´ h√†ng tr∆∞·ªõc kh√¥ng
                while col_index < num_columns and vmerge_tracking[col_index] is not None:
                    row_data[col_index] = vmerge_tracking[col_index]
                    col_index += 1
                    
                if col_index >= num_columns:
                    break
                
                # X·ª≠ l√Ω gridSpan (merge columns)
                grid_span = cell_element.xpath('./w:tcPr/w:gridSpan', namespaces=ns)
                span = 1
                if grid_span:
                    span_val = grid_span[0].get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val')
                    span = int(span_val) if span_val else 1
                
                # X·ª≠ l√Ω vMerge (merge rows)
                vmerge = cell_element.xpath('./w:tcPr/w:vMerge', namespaces=ns)
                is_vmerge_continue = False
                is_vmerge_start = False
                
                if vmerge:
                    vmerge_val = vmerge[0].get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', '')
                    is_vmerge_continue = vmerge_val != 'restart'
                    is_vmerge_start = vmerge_val == 'restart'
                
                # X·ª≠ l√Ω n·ªôi dung cell
                cell_paragraphs = cell_element.xpath('./w:p', namespaces=ns)
                cell_text_parts = [self._process_paragraph(p, ns) for p in cell_paragraphs]
                cell_text = '\n'.join(cell_text_parts).strip()
                
                # N·∫øu l√† vmerge continue, s·ª≠ d·ª•ng n·ªôi dung t·ª´ h√†ng tr∆∞·ªõc
                if is_vmerge_continue:
                    if col_index < len(vmerge_tracking) and vmerge_tracking[col_index] is not None:
                        cell_text = vmerge_tracking[col_index]
                
                # L∆∞u n·ªôi dung cell v√†o c·∫•u tr√∫c d·ªØ li·ªáu
                for j in range(col_index, min(col_index + span, num_columns)):
                    row_data[j] = cell_text
                    row_spans[j] = span if j == col_index else 0  # ƒê√°nh d·∫•u c√°c √¥ ƒë∆∞·ª£c merge
                
                # C·∫≠p nh·∫≠t vmerge tracking
                if is_vmerge_start or (vmerge and not is_vmerge_continue):
                    for j in range(col_index, min(col_index + span, num_columns)):
                        vmerge_tracking[j] = cell_text
                elif not vmerge:
                    for j in range(col_index, min(col_index + span, num_columns)):
                        vmerge_tracking[j] = None
                
                col_index += span
            
            table_data.append(row_data)
            cell_spans.append(row_spans)
        
        # T·∫°o b·∫£ng Markdown t·ª´ c·∫•u tr√∫c d·ªØ li·ªáu ƒë√£ ph√¢n t√≠ch
        for i, row_data in enumerate(table_data):
            # X·ª≠ l√Ω c√°c √¥ ƒë∆∞·ª£c merge theo chi·ªÅu ngang
            row_text = []
            for j, cell_text in enumerate(row_data):
                span = cell_spans[i][j]
                if span > 0:  # Ch·ªâ th√™m c√°c √¥ kh√¥ng b·ªã merge (ho·∫∑c l√† √¥ ƒë·∫ßu ti√™n c·ªßa m·ªôt nh√≥m merge)
                    # X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát trong Markdown
                    escaped_text = cell_text.replace('|', '\\|').replace('\n', '<br>')
                    row_text.append(escaped_text)
            
            # Th√™m d√≤ng v√†o b·∫£ng Markdown
            table_markdown_lines.append("| " + " | ".join(row_text) + " |")
            
            # Th√™m d√≤ng ph√¢n c√°ch sau h√†ng ƒë·∫ßu ti√™n
            if i == 0:
                separator = "| " + " | ".join(["---"] * len(row_text)) + " |"
                table_markdown_lines.append(separator)
        
        # Th√™m kho·∫£ng tr·ªëng tr∆∞·ªõc v√† sau b·∫£ng ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªãnh d·∫°ng Markdown ƒë√∫ng
        return "\n" + "\n".join(table_markdown_lines) + "\n"


    def _parse_docx(self, file_path: Path) -> Tuple[List[str], int]:
        """
        Ph√¢n t√≠ch t√†i li·ªáu DOCX v√† tr·∫£ v·ªÅ danh s√°ch c√°c ƒëo·∫°n vƒÉn v√† v·ªã tr√≠ c·ªßa TOC.
        """
        try:
            markdown_content = []
            toc_position = -1
            toc_found = False
            
            with zipfile.ZipFile(file_path, 'r') as docx_zip:
                xml_content = docx_zip.read('word/document.xml')
                root = etree.fromstring(xml_content)
                ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
                
                body = root.find('w:body', ns)
                if body is None:
                    return markdown_content, toc_position

                for i, element in enumerate(body.iterchildren()):
                    tag = etree.QName(element.tag).localname
                    
                    # Ki·ªÉm tra xem ƒë√¢y c√≥ ph·∫£i l√† TOC kh√¥ng
                    if tag == 'p':
                        processed_text = self._process_paragraph(element, ns)
                        
                        # Ki·ªÉm tra xem ƒëo·∫°n vƒÉn n√†y c√≥ ph·∫£i l√† ti√™u ƒë·ªÅ TOC kh√¥ng
                        if not toc_found and self._is_toc_heading(element, ns, processed_text):
                            toc_position = len(markdown_content)
                            toc_found = True
                            
                        markdown_content.append(processed_text)
                    elif tag == 'tbl':
                        processed_table = self._process_table(element, ns)
                        markdown_content.append(f"\n{processed_table}\n")
                    elif tag == 'sdt':
                        # Ki·ªÉm tra xem ƒë√¢y c√≥ ph·∫£i l√† TOC kh√¥ng
                        sdt_pr = element.find('.//w:sdtPr', ns)
                        if sdt_pr is not None:
                            tag_elem = sdt_pr.find('.//w:tag', ns)
                            if tag_elem is not None and 'TOC' in tag_elem.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', ''):
                                toc_position = len(markdown_content)
                                toc_found = True
                                
                                # X·ª≠ l√Ω n·ªôi dung b√™n trong TOC
                                content_elem = element.find('.//w:sdtContent', ns)
                                if content_elem is not None:
                                    for child in content_elem.iterchildren():
                                        child_tag = etree.QName(child.tag).localname
                                        if child_tag == 'p':
                                            processed_text = self._process_paragraph(child, ns)
                                            markdown_content.append(processed_text)
                                        elif child_tag == 'tbl':
                                            processed_table = self._process_table(child, ns)
                                            markdown_content.append(f"\n{processed_table}\n")
 
            return markdown_content, toc_position
        
        except KeyError:
            self.logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y 'word/document.xml' trong t·ªáp: {file_path}")
            return [], -1
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è ƒê√£ x·∫£y ra l·ªói khi tr√≠ch xu·∫•t t·ªáp Word '{file_path}': {e}")
            return [], -1

    def _is_toc_heading(self, para_element, ns, text: str) -> bool:
        """Ki·ªÉm tra xem ƒëo·∫°n vƒÉn c√≥ ph·∫£i l√† ti√™u ƒë·ªÅ TOC kh√¥ng."""
        # Ki·ªÉm tra style
        style = para_element.find('.//w:pStyle', ns)
        if style is not None:
            style_val = style.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', '')
            if 'TOCHeading' in style_val:
                return True
        
        # Ki·ªÉm tra n·ªôi dung
        toc_keywords = ["m·ª•c l·ª•c", "table of contents", "n·ªôi dung", "contents"]
        text_lower = text.lower().strip()
        return any(keyword in text_lower for keyword in toc_keywords)

    def extract_toc(self, file_path: Path) -> List[dict]:
        """Tr√≠ch xu·∫•t m·ª•c l·ª•c (Table of Contents) t·ª´ t√†i li·ªáu Word."""
        try:
            self.logger.info(f"üìë ƒêang tr√≠ch xu·∫•t m·ª•c l·ª•c t·ª´: {file_path.name}")
            toc_entries = []
            
            # ƒê·∫£m b·∫£o file l√† .docx
            docx_path = file_path
            if file_path.suffix.lower() == '.doc':
                docx_path = self._convert_doc_to_docx(file_path)
            
            # M·ªü file docx nh∆∞ m·ªôt zip archive
            with ZipFile(docx_path, 'r') as docx_zip:
                # ƒê·ªçc document.xml
                doc_xml = docx_zip.read('word/document.xml')
                
                # Parse XML
                root = ET.fromstring(doc_xml)
                
                # Namespace cho Word XML
                ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
                
                # T√¨m t·∫•t c·∫£ c√°c tr∆∞·ªùng TOC
                sdt_elements = root.findall('.//w:sdt', ns)
                
                for sdt in sdt_elements:
                    # Ki·ªÉm tra xem ƒë√¢y c√≥ ph·∫£i l√† TOC kh√¥ng
                    sdt_pr = sdt.find('.//w:sdtPr', ns)
                    if sdt_pr is not None:
                        tag = sdt_pr.find('.//w:tag', ns)
                        if tag is not None and 'TOC' in tag.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', ''):
                            # ƒê√¢y l√† TOC, tr√≠ch xu·∫•t c√°c m·ª•c
                            paragraphs = sdt.findall('.//w:p', ns)
                            
                            for p in paragraphs:
                                # B·ªè qua ti√™u ƒë·ªÅ TOC
                                if p.find('.//w:pStyle[@w:val="TOCHeading"]', ns) is not None:
                                    continue
                                    
                                # X√°c ƒë·ªãnh c·∫•p ƒë·ªô c·ªßa m·ª•c TOC
                                style = p.find('.//w:pStyle', ns)
                                level = 1  # M·∫∑c ƒë·ªãnh l√† c·∫•p ƒë·ªô 1
                                
                                if style is not None:
                                    style_val = style.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', '')
                                    if 'TOC' in style_val:
                                        try:
                                            level_str = ''.join(filter(str.isdigit, style_val))
                                            if level_str:
                                                level = int(level_str)
                                        except ValueError:
                                            pass
                                
                                # L·∫•y n·ªôi dung vƒÉn b·∫£n
                                text_elements = p.findall('.//w:t', ns)
                                text = ''.join(t.text for t in text_elements if t.text)
                                
                                if text.strip():
                                    toc_entries.append({
                                        'level': level,
                                        'text': text.strip(),
                                    })
                
                # N·∫øu kh√¥ng t√¨m th·∫•y TOC th√¥ng qua sdt, th·ª≠ ph∆∞∆°ng ph√°p kh√°c
                if not toc_entries:
                    # T√¨m c√°c ƒëo·∫°n vƒÉn c√≥ style TOC
                    paragraphs = root.findall('.//w:p', ns)
                    
                    for p in paragraphs:
                        style = p.find('.//w:pStyle', ns)
                        if style is not None:
                            style_val = style.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val', '')
                            if 'TOC' in style_val:
                                # X√°c ƒë·ªãnh c·∫•p ƒë·ªô
                                level = 1
                                try:
                                    level_str = ''.join(filter(str.isdigit, style_val))
                                    if level_str:
                                        level = int(level_str)
                                except ValueError:
                                    pass
                                    
                                # L·∫•y n·ªôi dung vƒÉn b·∫£n
                                text_elements = p.findall('.//w:t', ns)
                                text = ''.join(t.text for t in text_elements if t.text)
                                
                                if text.strip():
                                    toc_entries.append({
                                        'level': level,
                                        'text': text.strip(),
                                    })
            
            # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y TOC, th·ª≠ ph∆∞∆°ng ph√°p cu·ªëi c√πng: t√¨m c√°c heading
            if not toc_entries:
                self.logger.info("Kh√¥ng t√¨m th·∫•y TOC, ƒëang tr√≠ch xu·∫•t t·ª´ c√°c heading...")
                doc = Document(docx_path)
                
                for para in doc.paragraphs:
                    if para.style and para.style.name.startswith('Heading'):
                        try:
                            level_str = ''.join(filter(str.isdigit, para.style.name))
                            level = int(level_str) if level_str else 1
                        except ValueError:
                            level = 1
                            
                        if para.text.strip():
                            toc_entries.append({
                                'level': level,
                                'text': para.text.strip(),
                            })
            
            # N·∫øu file l√† .doc, x√≥a file t·∫°m sau khi x·ª≠ l√Ω xong
            if file_path.suffix.lower() == '.doc' and docx_path != file_path:
                try:
                    os.remove(docx_path)
                    os.rmdir(docx_path.parent)
                except Exception:
                    pass
            
            self.logger.info(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(toc_entries)} m·ª•c trong TOC")
            return toc_entries
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói khi tr√≠ch xu·∫•t TOC: {e}")
            return []

    def toc_to_markdown(self, toc_entries: List[dict]) -> str:
        """Chuy·ªÉn ƒë·ªïi TOC th√†nh ƒë·ªãnh d·∫°ng Markdown."""
        if not toc_entries:
            return ""
            
        markdown_lines = ["## M·ª•c l·ª•c\n"]
        
        for entry in toc_entries:
            indent = "  " * (entry['level'] - 1)
            markdown_lines.append(f"{indent}- {entry['text']}")
        
        return "\n".join(markdown_lines)

    def parse(self, file_path: str) -> ParsedResult:
        """Parse t√†i li·ªáu Word v√† gi·ªØ TOC ·ªü ƒë√∫ng v·ªã tr√≠ c·ªßa n√≥."""
        file_path = Path(file_path)
        ext = file_path.suffix.lower()
        self.logger.info(f"üìÑ ƒêang x·ª≠ l√Ω file Word: {file_path.name}")

        try:
            docx_path = file_path
            if ext == ".doc":
                docx_path = self._convert_doc_to_docx(file_path)
            elif ext != ".docx":
                self.logger.warning(f"‚ö†Ô∏è ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£: {ext}")
                return ParsedResult(is_success=False, content="", failed_reason=f"ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£: {ext}")
            
            # Ph√¢n t√≠ch t√†i li·ªáu v√† x√°c ƒë·ªãnh v·ªã tr√≠ TOC
            markdown_paragraphs, toc_position = self._parse_docx(docx_path)
            # Tr√≠ch xu·∫•t TOC
            toc_entries = self.extract_toc(docx_path)
            toc_markdown = self.toc_to_markdown(toc_entries)
            
            # N·∫øu t√¨m th·∫•y v·ªã tr√≠ TOC, ch√®n TOC v√†o ƒë√∫ng v·ªã tr√≠ ƒë√≥
            if toc_position >= 0 and toc_markdown:
                # X√≥a c√°c ƒëo·∫°n vƒÉn TOC g·ªëc (th∆∞·ªùng l√† 1 ƒëo·∫°n ti√™u ƒë·ªÅ)
                markdown_paragraphs[toc_position] = toc_markdown
            elif toc_markdown:  # N·∫øu kh√¥ng t√¨m th·∫•y v·ªã tr√≠ TOC nh∆∞ng c√≥ TOC
                # Th√™m TOC v√†o ƒë·∫ßu t√†i li·ªáu
                markdown_paragraphs.insert(0, toc_markdown)
            
            # X√≥a file t·∫°m n·∫øu l√† .doc
            if ext == ".doc" and docx_path != file_path:
                try:
                    os.remove(docx_path)
                    os.rmdir(docx_path.parent)
                    self.logger.debug(f"üßπ ƒê√£ xo√° file t·∫°m {docx_path}")
                except Exception as cleanup_err:
                    self.logger.warning(f"‚ö†Ô∏è Kh√¥ng xo√° ƒë∆∞·ª£c file t·∫°m: {cleanup_err}")
            
            return ParsedResult(is_success=True, content="\n\n".join(markdown_paragraphs))

        except Exception as e:
            self.logger.critical(f"üî• L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω {file_path.name}: {e}")
            return ParsedResult(is_success=False, content="", failed_reason="L·ªói khi x·ª≠ l√Ω file")
